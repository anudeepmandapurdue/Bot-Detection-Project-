{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6d420abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing human logs...\n",
      "Processing bot logs...\n",
      "SUCCESS: Full Numerical Dataset Created!\n",
      "Total rows: 186\n",
      "     unix_now  method_encoded  has_referer         rpm  unique_paths  \\\n",
      "0  1572364236               0            1  123.870968            17   \n",
      "1  1572359241               0            1   44.074074            14   \n",
      "2  1572341919               0            1   39.742765            17   \n",
      "3  1572365054               0            1   47.142857            14   \n",
      "4  1572389873               0            1   38.400000            17   \n",
      "\n",
      "   os_encoded  total_hits  is_bot  \n",
      "0           2          64       0  \n",
      "1           2         119       0  \n",
      "2           2         206       0  \n",
      "3           2          88       0  \n",
      "4           2         224       0  \n",
      "SUCCESS: Full Numerical Dataset Created!\n",
      "Total rows: 186\n",
      "     unix_now  method_encoded  has_referer         rpm  unique_paths  \\\n",
      "0  1572364236               0            1  123.870968            17   \n",
      "1  1572359241               0            1   44.074074            14   \n",
      "2  1572341919               0            1   39.742765            17   \n",
      "3  1572365054               0            1   47.142857            14   \n",
      "4  1572389873               0            1   38.400000            17   \n",
      "\n",
      "   os_encoded  total_hits  is_bot  \n",
      "0           2          64       0  \n",
      "1           2         119       0  \n",
      "2           2         206       0  \n",
      "3           2          88       0  \n",
      "4           2         224       0  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 1. SETUP: Regex and Helpers\n",
    "# CORRECTED: Logs start with \"- -\" (no IP), then timestamp, then method, path, status, size, referer, session_id, user_agent\n",
    "LOG_PATTERN = r'- - \\[(?P<timestamp>.*?)\\] \"(?P<method>\\w+)\\s+(?P<path>.*?)\\s+HTTP\\/.*?\"\\s+(?P<status>\\d+)\\s+(?P<size>\\d+)\\s+\"(?P<referer>.*?)\"\\s+(?P<session_id>[\\w-]+)\\s+\"(?P<user_agent>.*?)\"$'\n",
    "\n",
    "def extract_os_label(ua_string):\n",
    "    ua = ua_string.lower()\n",
    "    if 'windows' in ua: return 'Windows'\n",
    "    if 'linux' in ua: return 'Linux'\n",
    "    if 'ubuntu' in ua: return 'Ubuntu'\n",
    "    if 'mac' in ua: return 'MacOS'\n",
    "    return 'Unknown'\n",
    "\n",
    "def process_log_to_numerical(file_path, label):\n",
    "    raw_data = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            match = re.match(LOG_PATTERN, line.strip())\n",
    "            if match:\n",
    "                raw_data.append(match.groupdict())\n",
    "    \n",
    "    if not raw_data:\n",
    "        print(f'ERROR: No lines matched regex in {file_path}')\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    df = pd.DataFrame(raw_data)\n",
    "    df['session_id'] = df['session_id'].replace('-', 'none')\n",
    "    \n",
    "    # Convert timestamp string to datetime object\n",
    "    df['dt_obj'] = pd.to_datetime(df['timestamp'], format='%d/%b/%Y:%H:%M:%S %z')\n",
    "    \n",
    "    # Convert to Unix Timestamp (Seconds) - This is your \"Date.now()\" equivalent\n",
    "    df['unix_timestamp'] = df['dt_obj'].astype('int64') // 10**9\n",
    "\n",
    "    # 2. AGGREGATION: Grouping into behavioral sessions\n",
    "    sessions = df.groupby('session_id').agg(\n",
    "        total_hits=('dt_obj', 'count'),\n",
    "        unique_paths=('path', 'nunique'),\n",
    "        start_ts=('dt_obj', 'min'),\n",
    "        end_ts=('dt_obj', 'max'),\n",
    "        # New requested fields\n",
    "        unix_now=('unix_timestamp', 'first'), # The \"Date.now()\" of the first hit\n",
    "        method_raw=('method', 'first'),\n",
    "        referer_raw=('referer', 'first'),\n",
    "        ua_raw=('user_agent', 'first')\n",
    "    ).reset_index()\n",
    "\n",
    "    # 3. NUMERICAL FEATURE ENGINEERING\n",
    "    # RPM Calculation\n",
    "    duration_min = (sessions['end_ts'] - sessions['start_ts']).dt.total_seconds() / 60\n",
    "    sessions['rpm'] = sessions['total_hits'] / duration_min.replace(0, 1)\n",
    "\n",
    "    # 4. ENCODING STRINGS TO NUMBERS\n",
    "    # OS Encoding\n",
    "    os_map = {'Windows': 1, 'Linux': 2, 'Ubuntu': 3, 'MacOS': 4, 'Unknown': 0}\n",
    "    sessions['os_encoded'] = sessions['ua_raw'].apply(extract_os_label).map(os_map)\n",
    "    \n",
    "    # Method Encoding (Label Encoding)\n",
    "    # GET=0, POST=1, others=2\n",
    "    method_map = {'GET': 0, 'POST': 1}\n",
    "    sessions['method_encoded'] = sessions['method_raw'].map(lambda x: method_map.get(x, 2))\n",
    "    \n",
    "    # Referer Encoding (Binary: 1 if exists, 0 if direct \"-\")\n",
    "    sessions['has_referer'] = sessions['referer_raw'].apply(lambda x: 0 if x == '-' else 1)\n",
    "\n",
    "    # 5. FINAL SELECTION: Only Numerical Columns\n",
    "    final_df = sessions[[\n",
    "        'unix_now',       # Date.now() equivalent\n",
    "        'method_encoded', # GET/POST/PUT as numbers\n",
    "        'has_referer',    # Referer vs Direct as 1/0\n",
    "        'rpm', \n",
    "        'unique_paths', \n",
    "        'os_encoded', \n",
    "        'total_hits'\n",
    "    ]].copy()\n",
    "    \n",
    "    final_df['is_bot'] = label\n",
    "    return final_df\n",
    "\n",
    "# --- EXECUTION ---\n",
    "print('Processing human logs...')\n",
    "human_numerical = process_log_to_numerical('web_bot_detection_dataset/phase1/data/web_logs/humans/access_1.log', label=0)\n",
    "\n",
    "print('Processing bot logs...')\n",
    "bot_numerical = process_log_to_numerical('web_bot_detection_dataset/phase1/data/web_logs/bots/access_advanced_bots.log', label=1)\n",
    "\n",
    "master_dataset = pd.concat([human_numerical, bot_numerical], ignore_index=True)\n",
    "master_dataset.to_csv('final_numerical_dataset.csv', index=False)\n",
    "\n",
    "print('SUCCESS: Full Numerical Dataset Created!')\n",
    "print(f'Total rows: {len(master_dataset)}')\n",
    "print(master_dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528798d2",
   "metadata": {},
   "source": [
    "# Feature Engineering Guide: What You Can Extract\n",
    "\n",
    "## Currently Captured (8 features):\n",
    "1. `unix_now` - Timestamp of first request\n",
    "2. `method_encoded` - HTTP method type\n",
    "3. `has_referer` - Whether request came from referrer\n",
    "4. `rpm` - Requests per minute\n",
    "5. `unique_paths` - Number of different URLs accessed\n",
    "6. `os_encoded` - Operating system type\n",
    "7. `total_hits` - Total number of requests\n",
    "8. `is_bot` - Label (0=human, 1=bot)\n",
    "\n",
    "## NEW Features You Can Add (17 more):\n",
    "\n",
    "### **A. User-Agent Intelligence (3 features)**\n",
    "```\n",
    "1. ua_is_headless (BINARY: 0 or 1)\n",
    "   - Detects: \"HeadlessChrome\", \"headless\" in user agent\n",
    "   - Bot signal: Strong (headless browsers = automated)\n",
    "   - Source: User-Agent header\n",
    "   \n",
    "2. ua_length (NUMERIC)\n",
    "   - Length of user agent string\n",
    "   - Bot signal: Bots often have SHORT user agents (suspicious)\n",
    "   - Humans: Longer, browser-specific strings\n",
    "   - Source: User-Agent header\n",
    "   \n",
    "3. ua_has_mobile_keyword (BINARY: 0 or 1)\n",
    "   - Detect: \"Mobile\", \"Android\", \"iPhone\", \"iPad\"\n",
    "   - Bot signal: Mobile bots might not declare mobile\n",
    "   - Source: User-Agent header\n",
    "```\n",
    "\n",
    "### **B. Referer Analysis (3 features)**\n",
    "```\n",
    "4. referer_is_search_engine (BINARY)\n",
    "   - Domain check: google.com, bing.com, duckduckgo.com\n",
    "   - Bot signal: LOW (legitimate source)\n",
    "   - Source: Referer header\n",
    "   \n",
    "5. referer_is_social (BINARY)\n",
    "   - Domain check: facebook.com, twitter.com, reddit.com\n",
    "   - Bot signal: LOW (legitimate source)\n",
    "   - Source: Referer header\n",
    "   \n",
    "6. referer_is_suspicious (BINARY)\n",
    "   - Known bad domains, spam referrer lists\n",
    "   - Bot signal: HIGH\n",
    "   - Source: Referer header\n",
    "```\n",
    "\n",
    "### **C. Request Pattern Timing (4 features)**\n",
    "```\n",
    "7. request_interval_avg (NUMERIC: seconds)\n",
    "   - Average time between requests\n",
    "   - Formula: session_duration / (total_hits - 1)\n",
    "   - Bot signal: Humans have variable intervals, bots are regular\n",
    "   - Source: Timestamp between log entries\n",
    "   \n",
    "8. request_interval_variance (NUMERIC)\n",
    "   - How much request timing varies\n",
    "   - Bot signal: Low variance = bot (too regular)\n",
    "   - Source: Timestamp between log entries\n",
    "   \n",
    "9. burst_count (NUMERIC)\n",
    "   - Count of requests within 1 second\n",
    "   - Bot signal: Multiple requests/second = bot\n",
    "   - Source: Timestamp clustering\n",
    "   \n",
    "10. min_request_interval (NUMERIC: seconds)\n",
    "    - Fastest request interval\n",
    "    - Bot signal: Sub-second = likely bot\n",
    "    - Source: Timestamp between log entries\n",
    "```\n",
    "\n",
    "### **D. Path Pattern Analysis (4 features)**\n",
    "```\n",
    "11. path_depth_avg (NUMERIC)\n",
    "    - Average directory depth (e.g., /a = 1, /a/b/c = 3)\n",
    "    - Bot signal: Crawlers access deep paths\n",
    "    - Source: Path parsing\n",
    "    \n",
    "12. repeating_path_ratio (NUMERIC: 0.0-1.0)\n",
    "    - % of requests to same path\n",
    "    - Formula: (total_hits - unique_paths) / total_hits\n",
    "    - Bot signal: Crawlers visit MANY different paths\n",
    "    - Source: Path counting\n",
    "    \n",
    "13. parameter_count (NUMERIC)\n",
    "    - Average URL parameters per request\n",
    "    - Bot signal: Crawlers avoid complex parameters\n",
    "    - Source: URL parsing\n",
    "    \n",
    "14. path_contains_admin (BINARY)\n",
    "    - Access to /admin, /wp-admin, /api/admin\n",
    "    - Bot signal: HIGH (suspicious reconnaissance)\n",
    "    - Source: Path inspection\n",
    "```\n",
    "\n",
    "### **E. HTTP Status Patterns (3 features)**\n",
    "```\n",
    "15. error_4xx_ratio (NUMERIC: 0.0-1.0)\n",
    "    - % of 400-499 status codes\n",
    "    - Bot signal: HIGH (scanners hit 404s)\n",
    "    - Source: Status code analysis\n",
    "    \n",
    "16. error_5xx_ratio (NUMERIC: 0.0-1.0)\n",
    "    - % of 500-599 status codes\n",
    "    - Bot signal: Can be HIGH or LOW\n",
    "    - Source: Status code analysis\n",
    "    \n",
    "17. success_ratio (NUMERIC: 0.0-1.0)\n",
    "    - % of 200-299 status codes\n",
    "    - Bot signal: LOW success = bot/crawler\n",
    "    - Source: Status code analysis\n",
    "```\n",
    "\n",
    "### **F. Bandwidth Analysis (2 features)**\n",
    "```\n",
    "18. avg_response_size (NUMERIC: bytes)\n",
    "    - Average bytes per response\n",
    "    - Bot signal: Bots request differently\n",
    "    - Source: Response size header\n",
    "    \n",
    "19. total_bandwidth (NUMERIC: bytes)\n",
    "    - Sum of all response sizes\n",
    "    - Bot signal: Reflects request patterns\n",
    "    - Source: Response size header\n",
    "```\n",
    "\n",
    "### **G. Temporal Behavior (4 features)**\n",
    "```\n",
    "20. time_of_day (NUMERIC: 0-23)\n",
    "    - Hour when session started\n",
    "    - Bot signal: Off-hours activity suspicious\n",
    "    - Source: Timestamp\n",
    "    \n",
    "21. day_of_week (NUMERIC: 0-6, Mon=0)\n",
    "    - Day of week\n",
    "    - Bot signal: Bots work weekends/off-hours\n",
    "    - Source: Timestamp\n",
    "    \n",
    "22. is_off_hours (BINARY)\n",
    "    - 1 if before 9am or after 5pm\n",
    "    - Bot signal: HIGH (bots don't respect business hours)\n",
    "    - Source: Timestamp\n",
    "    \n",
    "23. session_duration_sec (NUMERIC: seconds)\n",
    "    - How long the session lasted\n",
    "    - Bot signal: Very short = bot, very long = human\n",
    "    - Source: end_ts - start_ts\n",
    "```\n",
    "\n",
    "### **H. Advanced Behavioral (4 features)**\n",
    "```\n",
    "24. method_variety (NUMERIC)\n",
    "    - Count of different HTTP methods used\n",
    "    - Bot signal: Bots mostly use GET\n",
    "    - Source: Method distribution\n",
    "    \n",
    "25. ratio_post_to_get (NUMERIC)\n",
    "    - POST requests / GET requests\n",
    "    - Bot signal: Very different patterns\n",
    "    - Source: Method distribution\n",
    "    \n",
    "26. returns_set_cookie (BINARY)\n",
    "    - Whether responses contain Set-Cookie header\n",
    "    - Bot signal: Humans accept cookies, bots might ignore\n",
    "    - Source: Response headers (from access logs)\n",
    "    \n",
    "27. cache_control_ignored (BINARY)\n",
    "    - Requests repeated to same path quickly (respects Cache-Control)\n",
    "    - Bot signal: Bots ignore caching\n",
    "    - Source: Path timestamps\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5beec32",
   "metadata": {},
   "source": [
    "# Can You Move Forward? YES - Here's The Complete Pipeline\n",
    "\n",
    "## The Full Architecture\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ PHASE 1: TRAINING (What you're doing now)                       â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                   â”‚\n",
    "â”‚  Access Logs (Historical)                                        â”‚\n",
    "â”‚  â”œâ”€ humans/access_1.log  (known humans)                         â”‚\n",
    "â”‚  â””â”€ bots/access_advanced_bots.log  (known bots)                 â”‚\n",
    "â”‚         â†“                                                         â”‚\n",
    "â”‚  Feature Extraction (31 features)                                â”‚\n",
    "â”‚         â†“                                                         â”‚\n",
    "â”‚  master_dataset.csv (186 rows labeled 0 or 1)                   â”‚\n",
    "â”‚         â†“                                                         â”‚\n",
    "â”‚  Train/Test Split (70/30)                                        â”‚\n",
    "â”‚         â†“                                                         â”‚\n",
    "â”‚  Train ML Model (RandomForest, LogisticRegression, etc.)        â”‚\n",
    "â”‚         â†“                                                         â”‚\n",
    "â”‚  Evaluate: Accuracy, Precision, Recall, F1-Score                â”‚\n",
    "â”‚         â†“                                                         â”‚\n",
    "â”‚  âœ… Save trained model to file (.pkl, .joblib)                  â”‚\n",
    "â”‚                                                                   â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ PHASE 2: REAL-TIME DETECTION (Production)                       â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                   â”‚\n",
    "â”‚  User makes request through proxy.js                             â”‚\n",
    "â”‚         â†“                                                         â”‚\n",
    "â”‚  eventStore.js records: path, method, user_agent, referer, etc. â”‚\n",
    "â”‚         â†“                                                         â”‚\n",
    "â”‚  Feature Extraction (calculate same 31 features):               â”‚\n",
    "â”‚    - rpm (from past 60s of events)                              â”‚\n",
    "â”‚    - unique_paths                                                â”‚\n",
    "â”‚    - ua_is_headless                                              â”‚\n",
    "â”‚    - time_of_day                                                 â”‚\n",
    "â”‚    - etc...                                                      â”‚\n",
    "â”‚         â†“                                                         â”‚\n",
    "â”‚  Load trained model                                              â”‚\n",
    "â”‚         â†“                                                         â”‚\n",
    "â”‚  model.predict(user_features) â†’ [0 or 1]                        â”‚\n",
    "â”‚         â†“                                                         â”‚\n",
    "â”‚  DECISION:                                                       â”‚\n",
    "â”‚    - 0 = HUMAN â†’ Allow traffic                                  â”‚\n",
    "â”‚    - 1 = BOT â†’ Block or Challenge                               â”‚\n",
    "â”‚         â†“                                                         â”‚\n",
    "â”‚  âœ… Update Redis cache & global reputation                      â”‚\n",
    "â”‚                                                                   â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "## Key Questions & Answers\n",
    "\n",
    "### **Q1: Can I actually use the dataset I created?**\n",
    "**YES, 100%** âœ…\n",
    "\n",
    "Your dataset:\n",
    "- âœ… Has labeled data (humans vs bots)\n",
    "- âœ… Has behavioral features that matter (RPM, unique paths, user agent patterns)\n",
    "- âœ… Matches what your proxy system actually tracks\n",
    "- âœ… 186 rows is small but workable for initial model\n",
    "\n",
    "### **Q2: Will my proxy features match the training features?**\n",
    "**YES, with caveats** âš ï¸\n",
    "\n",
    "**What matches perfectly:**\n",
    "- rpm, unique_paths, total_hits âœ…\n",
    "- os_encoded, method_encoded âœ…\n",
    "- has_referer, time_of_day âœ…\n",
    "- ua_is_headless âœ…\n",
    "\n",
    "**What you need to calculate in proxy:**\n",
    "- These features need to be calculated from RECENT events (last 60s, not full session)\n",
    "- Example: For RPM, calculate from `getEvents(tenant.id, ip)` in past 60s\n",
    "\n",
    "### **Q3: How do I integrate the model into proxy.js?**\n",
    "**Three-step process:**\n",
    "\n",
    "1. **Train model in Python** (notebook)\n",
    "   - Save as: `ml_model.joblib`\n",
    "   \n",
    "2. **Use model in Node.js** (proxy.js)\n",
    "   - Option A: Call Python subprocess\n",
    "   - Option B: Use ONNX to convert to JavaScript\n",
    "   - Option C: Create a separate ML microservice\n",
    "   \n",
    "3. **Calculate features in real-time**\n",
    "   - Same logic as training, but on fresh events\n",
    "\n",
    "### **Q4: What accuracy should I expect?**\n",
    "**Depends on data quality:**\n",
    "\n",
    "With your current dataset (186 rows):\n",
    "- Expected accuracy: 65-85%\n",
    "- Why: Small dataset, but clear signal\n",
    "\n",
    "With more data (1000+ rows):\n",
    "- Expected accuracy: 85-95%\n",
    "- You have multiple log files - use them all!\n",
    "\n",
    "### **Q5: Is 31 features too many?**\n",
    "**NO, but you can start with fewer** ğŸ“Š\n",
    "\n",
    "Start with these 10 \"core\" features:\n",
    "1. rpm\n",
    "2. unique_paths\n",
    "3. total_hits\n",
    "4. ua_is_headless\n",
    "5. time_of_day\n",
    "6. has_referer\n",
    "7. error_4xx_ratio\n",
    "8. session_duration_sec\n",
    "9. os_encoded\n",
    "10. method_encoded\n",
    "\n",
    "Then add more if accuracy is low."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
